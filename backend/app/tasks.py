from celery_app import celery_app
from utils.config import load_config
from utils.datahandler import load_and_transform_data
from utils.pipelines import run_base_plus_pipeline, run_base_pipeline
from utils.common import generate_monthly_period, setup_custom_logging
from utils.db_usage import upload_pipeline_result_to_db, SHEET_TO_TABLE, set_pipeline_column, export_pipeline_tables_to_excel, process_exchange_rate_file
from utils.training_status import training_status_manager
import os
from datetime import datetime

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è Celery worker —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–æ–≥–æ–≤
os.environ['CELERY_WORKER_PROCESS'] = '1'

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Celery worker
logger = setup_custom_logging(os.path.join(log_dir, "celery_worker.log"))

# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫—É—Ä—Å–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
EXCHANGE_RATE_FILE_PATH = os.getenv('EXCHANGE_RATE_FILE_PATH')

CONFIG_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../config_refined.yaml'))
RESULTS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../results'))
TRAINING_FILES_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'training_files'))

@celery_app.task(bind=True, track_started=True)
def train_task(self, pipeline, items_list, date, data_path, result_file_name):
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏ train_task: pipeline={pipeline}, items={len(items_list)}, date={date}")
    
    config = load_config(CONFIG_PATH)
    DATE_COLUMN = config['DATE_COLUMN']
    RATE_COLUMN = config['RATE_COLUMN']
    ITEM_ID = config['item_id']
    FACTOR = config['factor']
    models_to_use = config['models_to_use']
    TABPFNMIX_model = config.get('TABPFNMIX_model', {})
    METRIC = config['metric_for_training']
    ITEMS_TO_PREDICT = {key: config['–°—Ç–∞—Ç—å—è'][key] for key in items_list}
    CHOSEN_MONTH = datetime.strptime(date, "%Y-%m-%d")
    MONTHES_TO_PREDICT = generate_monthly_period(CHOSEN_MONTH)
    df_all_items = load_and_transform_data(data_path, DATE_COLUMN, RATE_COLUMN)
    
    logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(ITEMS_TO_PREDICT)} —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –ø–∞–π–ø–ª–∞–π–Ω–∞
    try:
        if EXCHANGE_RATE_FILE_PATH and os.path.exists(EXCHANGE_RATE_FILE_PATH):
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç –∏–∑ —Ñ–∞–π–ª–∞: {EXCHANGE_RATE_FILE_PATH}")
            exchange_result = process_exchange_rate_file(EXCHANGE_RATE_FILE_PATH, '–ö—É—Ä—Å', '–î–∞—Ç–∞')
            logger.info(f"–ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã: {exchange_result['message']}")
        else:
            logger.warning(f"–§–∞–π–ª –∫—É—Ä—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω: {EXCHANGE_RATE_FILE_PATH}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –∫—É—Ä—Å—ã –Ω–µ –æ–±–Ω–æ–≤–∏–ª–∏—Å—å
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è
    total_articles = len(ITEMS_TO_PREDICT)
    task_id = self.request.id
    training_status_manager.initialize_training(total_articles, task_id)
    logger.info(f"–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {total_articles} —Å—Ç–∞—Ç–µ–π")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ pipeline
    prev_path = os.path.join(TRAINING_FILES_DIR, f"prev_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx")
    output = export_pipeline_tables_to_excel(SHEET_TO_TABLE)
    with open(prev_path, "wb") as f:
        f.write(output.getvalue())
    logger.info(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {prev_path}")
    
    try:
        if pipeline == "BASE+":
            logger.info("–ó–∞–ø—É—Å–∫ BASE+ –ø–∞–π–ø–ª–∞–π–Ω–∞")
            run_base_plus_pipeline(
                df_all_items=df_all_items,
                ITEMS_TO_PREDICT=ITEMS_TO_PREDICT,
                config=config,
                DATE_COLUMN=DATE_COLUMN,
                RATE_COLUMN=RATE_COLUMN,
                ITEM_ID=ITEM_ID,
                FACTOR=FACTOR,
                models_to_use=models_to_use,
                TABPFNMIX_model=TABPFNMIX_model,
                METRIC=METRIC,
                CHOSEN_MONTH=CHOSEN_MONTH,
                MONTHES_TO_PREDICT=MONTHES_TO_PREDICT,
                result_file_name=result_file_name,
                prev_predicts_file=prev_path,
                status_manager=training_status_manager
            )
            logger.info("BASE+ –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î")
            upload_pipeline_result_to_db(result_file_name, SHEET_TO_TABLE, date, DATE_COLUMN)
            set_pipeline_column(DATE_COLUMN, date, 'BASE+')
            logger.info("–î–∞–Ω–Ω—ã–µ BASE+ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î")
            
        elif pipeline == "BASE":
            logger.info("–ó–∞–ø—É—Å–∫ BASE –ø–∞–π–ø–ª–∞–π–Ω–∞")
            run_base_pipeline(
                df_all_items=df_all_items,
                ITEMS_TO_PREDICT=ITEMS_TO_PREDICT,
                config=config,
                DATE_COLUMN=DATE_COLUMN,
                RATE_COLUMN=RATE_COLUMN,
                ITEM_ID=ITEM_ID,
                FACTOR=FACTOR,
                models_to_use=models_to_use,
                METRIC=METRIC,
                CHOSEN_MONTH=CHOSEN_MONTH,
                MONTHES_TO_PREDICT=MONTHES_TO_PREDICT,
                result_file_name=result_file_name,
                prev_predicts_file=prev_path,
                status_manager=training_status_manager
            )
            logger.info("BASE –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î")
            upload_pipeline_result_to_db(result_file_name, SHEET_TO_TABLE, date, DATE_COLUMN)
            set_pipeline_column(DATE_COLUMN, date, 'BASE')
            logger.info("–î–∞–Ω–Ω—ã–µ BASE –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î")
        
        # –ù–ï –æ—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ - –æ—Å—Ç–∞–≤–ª—è–µ–º task_id
        # –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ "done" –¥–æ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –û–ö
        
        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ train_task —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {result_file_name}")
        return {"status": "done", "result_file": os.path.basename(result_file_name)}
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ train_task: {e}", exc_info=True)
        # –û—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ –∏–ª–∏ –æ—Ç–º–µ–Ω–µ
        training_status_manager.clear_training_progress()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
        try:
            from celery.exceptions import Revoked
            if isinstance(e, Revoked):
                logger.warning("–ó–∞–¥–∞—á–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ (Revoked)")
                return {"status": "revoked", "error": "Task was revoked"}
        except ImportError:
            # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ Celery
            if 'revoked' in str(e).lower():
                logger.warning("–ó–∞–¥–∞—á–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ (revoked –≤ —Å—Ç—Ä–æ–∫–µ –æ—à–∏–±–∫–∏)")
                return {"status": "revoked", "error": "Task was revoked"}
        
        return {"status": "error", "error": str(e)}
