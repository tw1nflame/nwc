from celery_app import celery_app
from utils.config import load_config
from utils.datahandler import load_and_transform_data
from utils.pipelines import run_base_plus_pipeline, run_base_pipeline
from utils.common import generate_monthly_period, setup_custom_logging
from utils.db_usage import upload_pipeline_result_to_db, SHEET_TO_TABLE, set_pipeline_column, export_pipeline_tables_to_excel, process_exchange_rate_file
from utils.training_status import training_status_manager
import os
from datetime import datetime

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è Celery worker —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–æ–≥–æ–≤
os.environ['CELERY_WORKER_PROCESS'] = '1'

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Celery worker
logger = setup_custom_logging(os.path.join(log_dir, "celery_worker.log"))

CONFIG_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '../config_refined.yaml'))
RESULTS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../results'))
TRAINING_FILES_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'training_files'))

@celery_app.task(bind=True, track_started=True)
def train_task(self, pipeline, items_list, date, data_path, result_file_name):
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏ train_task: pipeline={pipeline}, items={len(items_list)}, date={date}")
    
    config = load_config(CONFIG_PATH)
    DATE_COLUMN = config['DATE_COLUMN']
    RATE_COLUMN = config['RATE_COLUMN']
    ITEM_ID = config['item_id']
    FACTOR = config['factor']
    models_to_use = config['models_to_use']
    TABPFNMIX_model = config.get('TABPFNMIX_model', {})
    METRIC = config['metric_for_training']
    ITEMS_TO_PREDICT = {key: config['–°—Ç–∞—Ç—å—è'][key] for key in items_list}
    CHOSEN_MONTH = datetime.strptime(date, "%Y-%m-%d")
    MONTHES_TO_PREDICT = generate_monthly_period(CHOSEN_MONTH)
    df_all_items = load_and_transform_data(data_path, DATE_COLUMN, RATE_COLUMN)
    
    logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(ITEMS_TO_PREDICT)} —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö
    try:
        if data_path and os.path.exists(data_path):
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç –∏–∑ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö: {data_path}")
            exchange_result = process_exchange_rate_file(data_path, '–ö—É—Ä—Å', '–î–∞—Ç–∞')
            logger.info(f"–ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã: {exchange_result['message']}")
        else:
            logger.warning(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –∫—É—Ä—Å—ã –Ω–µ –æ–±–Ω–æ–≤–∏–ª–∏—Å—å
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è
    total_articles = len(ITEMS_TO_PREDICT)
    task_id = self.request.id
    training_status_manager.initialize_training(total_articles, task_id)
    logger.info(f"–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {total_articles} —Å—Ç–∞—Ç–µ–π")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ pipeline
    prev_path = os.path.join(TRAINING_FILES_DIR, f"prev_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx")
    # –ü–µ—Ä–µ–¥–∞–µ–º pipeline ('base' –∏–ª–∏ 'base+') –≤ —Ñ—É–Ω–∫—Ü–∏—é —ç–∫—Å–ø–æ—Ä—Ç–∞
    pipeline_arg = None
    if pipeline == "BASE+":
        pipeline_arg = 'base+'
    elif pipeline == "BASE":
        pipeline_arg = 'base'
    output = export_pipeline_tables_to_excel(SHEET_TO_TABLE, pipeline=pipeline_arg)
    with open(prev_path, "wb") as f:
        f.write(output.getvalue())
    logger.info(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {prev_path}")
    
    try:
        if pipeline == "BASE+":
            logger.info("–ó–∞–ø—É—Å–∫ BASE+ –ø–∞–π–ø–ª–∞–π–Ω–∞")
            run_base_plus_pipeline(
                df_all_items=df_all_items,
                ITEMS_TO_PREDICT=ITEMS_TO_PREDICT,
                config=config,
                DATE_COLUMN=DATE_COLUMN,
                RATE_COLUMN=RATE_COLUMN,
                ITEM_ID=ITEM_ID,
                FACTOR=FACTOR,
                models_to_use=models_to_use,
                TABPFNMIX_model=TABPFNMIX_model,
                METRIC=METRIC,
                CHOSEN_MONTH=CHOSEN_MONTH,
                MONTHES_TO_PREDICT=MONTHES_TO_PREDICT,
                result_file_name=result_file_name,
                prev_predicts_file=prev_path,
                status_manager=training_status_manager
            )
            logger.info("BASE+ –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î")
            upload_pipeline_result_to_db(result_file_name, SHEET_TO_TABLE, date, DATE_COLUMN, pipeline='base+')
            logger.info("–î–∞–Ω–Ω—ã–µ BASE+ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î")
            
        elif pipeline == "BASE":
            logger.info("–ó–∞–ø—É—Å–∫ BASE –ø–∞–π–ø–ª–∞–π–Ω–∞")
            run_base_pipeline(
                df_all_items=df_all_items,
                ITEMS_TO_PREDICT=ITEMS_TO_PREDICT,
                config=config,
                DATE_COLUMN=DATE_COLUMN,
                RATE_COLUMN=RATE_COLUMN,
                ITEM_ID=ITEM_ID,
                FACTOR=FACTOR,
                models_to_use=models_to_use,
                METRIC=METRIC,
                CHOSEN_MONTH=CHOSEN_MONTH,
                MONTHES_TO_PREDICT=MONTHES_TO_PREDICT,
                result_file_name=result_file_name,
                prev_predicts_file=prev_path,
                status_manager=training_status_manager
            )
            logger.info("BASE –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î")
            upload_pipeline_result_to_db(result_file_name, SHEET_TO_TABLE, date, DATE_COLUMN, pipeline='base')
            logger.info("–î–∞–Ω–Ω—ã–µ BASE –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î")
        
        # –ü—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏:
        # 1. –û—á–∏—â–∞–µ–º current_article (–±–æ–ª—å—à–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º)
        training_status_manager.update_current_article('')
        
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ì–õ–û–ë–ê–õ–¨–ù–´–ô —Å—Ç–∞—Ç—É—Å –¥–ª—è –í–°–ï–• –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        training_status_manager.save_completed_training({
            'status': 'done',
            'message': '–ü—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î –∏ –≥–æ—Ç–æ–≤—ã –∫ –≤—ã–≥—Ä—É–∑–∫–µ!',
            'pipeline': pipeline,
            'date': date,
            'articles': list(ITEMS_TO_PREDICT.keys()),  # –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –∑–∞–ø—É—â–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ
            'completed_at': datetime.now().isoformat()
        })
        
        # 3. –í–ê–ñ–ù–û: –û—á–∏—â–∞–µ–º current_task_id - —Ä–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—É—Å–∫ –Ω–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        training_status_manager.redis_client.delete(training_status_manager.KEYS['current_task_id'])
        
        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ train_task —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {result_file_name}")
        return {"status": "done"}
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ train_task: {e}", exc_info=True)
        
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        training_status_manager.save_completed_training({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {str(e)}',
            'error': str(e),
            'articles': list(ITEMS_TO_PREDICT.keys()),  # –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∞ –ø–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è
            'completed_at': datetime.now().isoformat()
        })
        
        # –û—á–∏—â–∞–µ–º current_task_id –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
        training_status_manager.redis_client.delete(training_status_manager.KEYS['current_task_id'])
        training_status_manager.clear_training_progress()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
        try:
            from celery.exceptions import Revoked
            if isinstance(e, Revoked):
                logger.warning("–ó–∞–¥–∞—á–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ (Revoked)")
                return {"status": "revoked", "error": "Task was revoked"}
        except ImportError:
            # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ Celery
            if 'revoked' in str(e).lower():
                logger.warning("–ó–∞–¥–∞—á–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ (revoked –≤ —Å—Ç—Ä–æ–∫–µ –æ—à–∏–±–∫–∏)")
                return {"status": "revoked", "error": "Task was revoked"}
        
        return {"status": "error", "error": str(e)}
